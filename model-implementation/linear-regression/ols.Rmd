---
title: "Untitled"
author: "Andrew Chung"
date: "2025-05-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# BTRY 4100 - Final Project, Linear Model Implementation

Andrew Chung, hc893

```{r}
library(tidyverse)
library(MASS)
library(quantreg)
library(ggfortify)
library(ggplot2)
```

## Import Data Set

```{r}
data.raw = read.csv("subwaydata.csv")
data = data.raw[, -c(1:3)]
data.scaled = data %>%
  # center/scale predictors
  mutate(across(all_of(colnames(data)[-1]), scale)) %>%
  mutate(ridership = ridership/1000) # scale ridership to 1K

# juxtapose distributions of raw response (1K scaled) vs. log-transformed response
par(mfrow = c(1,2))
hist(data.scaled$ridership, breaks = 100, main = "Ridership (in thousands)")
hist(log(data$ridership), breaks = 100, main = "Log-Transformed Ridership")
```



## Run Ordinary Least Squares (OLS)

$$\mathbf{Y} = \mathbf{Xb} + \mathbf{\epsilon}$$

```{r}
lm1 = lm(ridership ~ ., data = data.scaled)
summary(lm1)
autoplot(lm1)

library(ggplot2)
qq_df <- data.frame(resid = resid(lm1))

ggplot(qq_df, aes(sample = resid)) +
  stat_qq(size = 1.5) +
  stat_qq_line(color = "darkred", linetype = "dashed") +
  labs(title = "Q–Q Plot of OLS Residuals",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal(base_size = 14)
```

```{r}
residuals = resid(lm1)
shapiro.test(residuals)
ks.test(scale(residuals), "pnorm", 0, 1)
```

### Box-Cox Plot

The Box-Cox transformation is defined as 

$$y^{(\lambda)} = \operatorname{ifelse}\bigg(\lambda\neq0, \frac{y^\lambda - 1}{\lambda}, \log(y)\bigg)$$

```{r}
bc = boxcox(
  lm1,
  plotit = TRUE,
  xlab = expression(lambda),
  ylab = "Log-Likelihood"
)
```

<JUSTIFICATION FOR LOG_TRANSFORMATION>

## OLS with Log Transformation of the Response

$$\log(\mathbf{Y}) = \mathbf{Xb} + \mathbf{\epsilon}$$

```{r}
data.scaled.log = data %>%
  # center/scale predictors
  mutate(across(all_of(colnames(data)[-1]), scale)) %>%
  mutate(ridership = log(ridership))
lm.log = lm(ridership ~ ., data = data.scaled.log)
summary(lm.log)

# residual diagnostics
autoplot(lm.log)

qq_df <- data.frame(resid = resid(lm.log))
ggplot(qq_df, aes(sample = resid)) +
  stat_qq(size = 1.5) +
  stat_qq_line(color = "darkred", linetype = "dashed") +
  labs(title = "Q–Q Plot of Log-Transformed OLS",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal(base_size = 14)
```

```{r}
residuals = resid(lm.log)
shapiro.test(residuals)
ks.test(scale(residuals), "pnorm", 0, 1)
```

### Quantile Plot on the Median

```{r}
rq.lm = rq(ridership ~ ., tau = 0.5, data = data.scaled.log)
summary(rq.lm, se = "boot", R = 200)

```

```{r}
par(mfrow = c(2,3))
avPlots(lm.log, ask = FALSE)
par(mfrow = c(1,1))
influencePlot(lm.log)

predictors <- names(lm.log$model)[-1]
for (var in predictors) {
  ggplot(lm.log$model, aes_string(x = var, y = residuals(lm.log))) +
    geom_point() +
    geom_smooth(method = "loess", se = FALSE) +
    labs(title = paste("Residuals vs", var),
         y = "Residuals") +
    theme_minimal() -> p
  print(p)
}

# 6) Non-constant variance test from car
ncvTest(lm.log)    # alternative to BP

# 7) Box–Cox (just to confirm)
boxCox(lm.log, lambda = seq(-1, 2, 0.1))
```


### Identify High-Leverage Points

```{r}
poi = c(64, 73, 163, 184)
data.raw[poi, ]
```

Important piece of information, data points 163 and 184 respectively represent Times Square-42 St and Grand Central stations -- both 
1. Major rail terminals at the heart of Manhattan's midtown
2. Served by the 42nd Street Shuttle (SG) (are the only 2 stations to do so)
3. Boast a monthly ridership of more than 1 million

I will add a new factor variable to represent stations with >1M monthly ridership, dubbed `is_hub`.

```{r}
data.log.fact = data.scaled.log %>%
  mutate(is_hub = ifelse(
    row_number() %in% c(163, 164, 183, 184), 1, 0
  ))

lm.log.fact = lm(ridership ~ ., data = data.log.fact)
summary(lm.log.fact)

# residual diagnostics
autoplot(lm.log.fact)

qq_df <- data.frame(resid = resid(lm.log.fact))
ggplot(qq_df, aes(sample = resid)) +
  stat_qq(size = 1.5) +
  stat_qq_line(color = "darkred", linetype = "dashed") +
  labs(title = "Q–Q Plot of Log-Transformed OLS",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal(base_size = 14)
```

Below is the re-fit log model without the hub data points.

```{r}
data.filtered = data.scaled.log[-c(163, 164, 183, 184), ]
lm.filt = lm(ridership ~ ., data = data.filtered)
summary(lm.filt)
autoplot(lm.filt)

qq_df <- data.frame(resid = resid(lm.filt))
ggplot(qq_df, aes(sample = resid)) +
  stat_qq(size = 1.5) +
  stat_qq_line(color = "darkred", linetype = "dashed") +
  labs(title = "Q–Q Plot of Log-Transformed OLS",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal(base_size = 14)
```

-----------------------------------------------------

```{r}
library(car)
vif_full <- vif(lm.filt)
print(vif_full)
```

## Principal Component Regression (PCR)

```{r}
# k = 2 or k = 3
pcr.lm = pcr(ridership ~ .,
             data = data.filtered,
             scale = FALSE, ncomp = 3,
             validation = "none")
summary(pcr.lm)
evr = explvar(pcr.lm) / 100
cum.exp = cumsum(evr)
```

```{r}
# Loadings for each component
loadings.df <- as.data.frame(loadings(pcr.lm)[, 1:k])
colnames(loadings.df) <- paste0("PC", 1:k)
print(loadings.df)

# intercept + slopes for each of the perf_vars
coef_pcr <- coef(pcr.lm, ncomp = k, intercept = TRUE)
#print(coef_pcr)

# Fitted & residuals
fitted_pcr <- predict(pcr.lm, ncomp = k, newdata = data.scaled.log)
resid_pcr  <- data.scaled.log$ridership - as.vector(fitted_pcr)

# Residuals vs Fitted
qqnorm(resid_pcr, main = "Q–Q Plot of PCR Residuals"); qqline(resid_pcr)
plot(fitted_pcr, resid_pcr,
     xlab = "Fitted (PCR)", ylab = "Residuals",
     main = "Residuals vs Fitted (PCR)")
abline(h = 0, lty = "dashed")

```

```{r}
# obtain loading matrix, compute PC scores
pc.scores = as.data.frame(
  as.matrix(data.filtered[, -1]) %*% as.matrix(loadings.df)
)
pc.scores$y <- data.filtered$ridership

lm.pc <- lm(y ~ ., data = pc.scores)
summary(lm.pc)
```

```{r}
cor(data.filtered[, -1])
corr.plot = ggpairs(data.filtered[, -1])# + scale_x_continuous(n.breaks = 3) + scale_x_continuous(n.breaks = 3)
# imported to final report but not displayed on the document due to figure margin constraints.
```

```{r}
data.exp.log = data.raw[, -c(1,3)] %>%
  mutate(
    infra = infra_critical + infra_noncritical,
    noninfra = noninfra_critical + noninfra_noncritical
  ) %>%
  dplyr::select(-infra_critical, -infra_noncritical, -noninfra_critical, -noninfra_noncritical) %>%
  mutate(s = strsplit(lines, ","), n_lines = lengths(s)) %>%
  dplyr::select(-lines, -s) %>%
  mutate(across(1:10, ~ ./n_lines)) %>%
  mutate(ridership = log(ridership), n_lines = log(n_lines))

lm.exp = lm(ridership ~ ., data = data.exp.log)
summary(lm.exp)
```

Below is the re-fit log model without the hub data points.

```{r}
# illustrating the outsized influence of points 163, 164, 183, 184
influencePlot(lm.log)

data.filtered = data.log[-c(163, 164, 183, 184), ]
lm.filt = lm(ridership ~ ., data = data.filtered)
summary(lm.filt)
autoplot(lm.filt)

# residuals test
residuals = resid(lm.filt)
shapiro.test(residuals)
ks.test(scale(residuals), "pnorm", 0, 1)

# VIFs
vif(lm.filt)
```

